import h5py
import json
import numpy as np
import pandas as pd

from bisect import bisect_left, bisect_right
from math import floor

# from memory_profiler import profile

from data_link import *
from dev_helper import record_nm


class EcgRecord:
    """Handles reading a .h5 file of ECG signal data, and sending datasets to graph plot.

    The .h5 file is created by `Ablation Database (ABLDB)`.
    Each .h5 file, contains a collection of .log files for a single surgery.
    Each .log file is a ECG signal dataset generated by sensor by Abbott,
    and it's one Segment of signal taken, artificially sliced.

    All .log files joined sequentially will form the entire sampling of all ECG data in the surgery.
    """

    EPOCH_START = pd.Timestamp('1970-01-01')
    TIME_STRT = str(EPOCH_START)
    UNIT_1US = pd.Timedelta(1, unit='us')
    FMT_TMLB = '%H:%M:%S.%f'

    # @profile
    def __init__(self, path):
        self.record = h5py.File(path, 'r')
        self._seg_keys = list(self.record.keys())  # keys to each segment compiled in the .h5 file
        self.annotatns = json.loads(self.record.attrs['annotations'])

        # Following properties are the same across different segments, as far as EcgApp is concerned.
        metadata = self._get_seg(self._seg_keys[0]).get_metadata()
        self.spl_rate = metadata['sample_rate']
        # Multiplying factor for converting to time in microseconds
        self.FAC_TO_US = 10 ** 6 / self.spl_rate
        self.lead_nms = [lead['name'] for lead in metadata['sigheader']]

        self._sample_counts = self._get_sample_counts()
        self._sample_counts_acc = self._get_sample_counts_acc()  # Accumulated
        self.COUNT_END = self._sample_counts_acc[-1] - 1
        self.TIME_END = str(self.count_to_pd_time(self.COUNT_END))

    def _get_sample_counts(self):
        """ Helps to check which segment(s) is a time range located in """
        sample_counts = []
        for key in self._seg_keys:
            sample_counts.append(self.record[key].shape[1])
        return sample_counts

    def _get_sample_counts_acc(self):
        lst = [self._sample_counts[0]]
        for i, v in enumerate(self._sample_counts[1:]):
            val = v + lst[i]
            lst.append(val)
        return lst

    # def num_sample_count(self):
    #     return self._sample_counts_acc[-1] - 1

    def _get_seg(self, key):
        """
        :param key: A key to a segment in the internal dictionary
        :return: A single segment
        """
        return self.Segment(self.record[key])

    def _get_dset_by_idx(self, idx_seg):
        """
        Syntactic sugar for getting dataset of a segment

        .. note:: Can't further read in a channel by index *while adopting* array slicing
        """
        return self.record[self._seg_keys[idx_seg]]

    def get_annotation_header(self):
        return self.annotatns[0]

    def get_annotations(self):
        """
        :return: All annotations across all segments
        """
        return self.annotatns[2:]  # The first 2 elements are header and protocol respectively

    class Segment:
        """
        Each segment contains multiple `leads` taking in data concurrently
        """

        def __init__(self, dataset):
            """:param: dataset: A dataset in a .h5 file, 2 dimensional, #leads * #sample """
            self.dataset = dataset

        def get_metadata(self):
            return json.loads(self.dataset.attrs['metadata'])

    def _locate_seg_idx(self, strt, end):
        """ Locates the segment(s) the sample_range spans, by index

        :param strt: integer start sample-count
        :param end: integer end sample-count
        :return: start, end segment-index tuple

        .. note:: In desencding frequency, sample_range should lie in 1 segment, or 2 segments if at edge, \\
        or multiple segments on sample global view
        """
        # Edge case when idx_end = edge of segment start, still need to include that 1 value hence `bisect_right`
        return bisect_left(self._sample_counts_acc, strt), bisect_right(self._sample_counts_acc, end)

    # @profile
    def get_ecg_samples(self, idx_lead, strt, end, step):
        """ Continuous samples of ecg magnitudes, specified by counted range

        :param idx_lead: index of the lead
        :param strt: start sample count
        :param end: end sample count
        :param step: every `step`-th value in the data sample is included
        :return: 1D array of ecg values

        .. note:: optimized for large sample_range
        .. seealso:: `EcgApp._Plot.get_fig()`
        """
        idx_strt, idx_end = self._locate_seg_idx(strt, end)
        if idx_strt != 0:
            strt = strt - self._sample_counts_acc[idx_strt-1]
        if idx_end != 0:
            end = end - self._sample_counts_acc[idx_end-1] + 1  # for inclusive end
        if idx_strt == idx_end:
            return self._get_dset_by_idx(idx_strt)[idx_lead, strt:end:step]
        else:
            dset = self._get_dset_by_idx(idx_strt)
            parts = [dset[idx_lead, strt::step]]
            # e.g. Shape is 20 so indices [0, 19], strt is 2 and step is 7
            # => returns values at indices 2, 9, 16 with 3 elements remaining
            offset_prev = self._get_prev_remaining_offset(dset.shape[1], strt, step)
            for i in range(idx_strt+1, idx_end):  # for range()'s exclusive end
                dset = self._get_dset_by_idx(i)
                # The new start index relative to this segment, note 0-indexing
                strt = step-1 - offset_prev  # Sanity check: the new `strt` is in the range [0, step)
                parts.append(dset[idx_lead, strt::step])
                offset_prev = self._get_prev_remaining_offset(dset.shape[1], strt, step)
            strt = step-1 - offset_prev
            parts.append(self._get_dset_by_idx(idx_end)[idx_lead, strt:end:step])
            return np.concatenate(parts)

    @staticmethod
    def _get_prev_remaining_offset(sz_arr, strt, step):
        """
        So that stepping across multiple array segments behaves as if a single array

        Achieved by carrying over `step` offsets

        :return: Integer in range [0, step)
        """
        return (sz_arr-1 - strt) % step

    def get_global_samples(self, idx_lead, step):
        """ For plot global thumbnail, data taken at large samples """
        parts = []
        for k in self._seg_keys:
            parts.append(self.record[k][idx_lead, ::step])
        return np.concatenate(parts)

    def get_time_values(self, strt, end, step):
        """
        :return: Evenly spaced array of incremental time stamps, created in microseconds
        """
        counts = np.linspace(strt, end, num=self._count_indexing_num(strt, end, step))
        return pd.to_datetime(pd.Series(self._counts_to_us(counts)), unit='us')

    @staticmethod
    def _count_indexing_num(strt, end, step):
        """Counts the number of elements as result of numpy array indexing """
        num = (end - strt) // step
        # if (end - strt) % step != 0:
        #     num += 1
        return num + 1

    def _counts_to_us(self, counts):
        # Converted to time in microseconds as integer, drastically raises efficiency while maintaining precision
        if floor(self.FAC_TO_US) == self.FAC_TO_US:  # Is an int
            return counts * int(self.FAC_TO_US)
        else:
            return (counts * self.FAC_TO_US).astype(np.int64)

    def get_time_values_delta(self, strt, end, step):
        """ For external export """
        counts = np.linspace(strt, end, num=self._count_indexing_num(strt, end, step))
        return pd.to_timedelta(pd.Series(self._counts_to_us(counts)), unit='us')

    def time_str_to_count(self, time):
        """
        Within range [0, maximum sample count)
        """
        return self.keep_range(self.time_to_count(pd.Timestamp(time) - self.EPOCH_START))

    def time_to_count(self, t):
        """
        :param t: pandas time object
        .. note:: Doesn't check valid record indexing
        """
        # Optimization: integer instead of float arithmetic while preserving accuracy
        t_us = t // self.UNIT_1US
        return t_us * self.spl_rate // (10 ** 6)

    def keep_range(self, count):
        """ Make sure the index into record stays within bounds """
        return min(max(0, count), self._sample_counts_acc[-1] - 1)

    def count_to_pd_time(self, count):
        time_us = count * (10 ** 6) // self.spl_rate
        return pd.to_datetime(time_us, unit='us')

    def count_to_str(self, count):
        """
        :return: Human-readable time string, specialized to typical ecg range """
        return self.count_to_pd_time(count).strftime(self.FMT_TMLB)[1:-5]

    def pd_time_to_str(self, t):
        return t.strftime(self.FMT_TMLB)[1:-5]

    def get_range(self):
        """ Human-readable, inclusive start and exclusive end time of current record """
        return [
            self.count_to_pd_time(0),
            self.count_to_pd_time(self._sample_counts_acc[-1])
        ]

    @staticmethod
    def example(path=DATA_PATH.joinpath(record_nm)):
        """Fast process a simple example for testing """
        return EcgRecord(path)


if __name__ == "__main__":
    help(EcgRecord)
